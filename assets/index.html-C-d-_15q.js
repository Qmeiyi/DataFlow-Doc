import{_ as e,c as a,b as n,o as d}from"./app-DT4DhCK_.js";const r={};function i(s,t){return d(),a("div",null,t[0]||(t[0]=[n('<h2 id="overview" tabindex="-1"><a class="header-anchor" href="#overview"><span>Overview</span></a></h2><table><thead><tr><th>Category</th><th>Number of Scorers</th><th>Description</th></tr></thead><tbody><tr><td>Word Overlap Based</td><td>5</td><td>Evaluates the n-gram overlap between generated and reference texts</td></tr><tr><td>Word Embeddings Based</td><td>2</td><td>Uses word embeddings to calculate similarity between generated and reference texts</td></tr><tr><td>Language Models Based</td><td>4</td><td>Utilizes pre-trained language models to evaluate semantics and fluency</td></tr><tr><td>Others</td><td>2</td><td>-</td></tr></tbody></table><hr><h2 id="word-overlap-based" tabindex="-1"><a class="header-anchor" href="#word-overlap-based"><span>Word Overlap Based</span></a></h2><table><thead><tr><th>Scorer Name</th><th>Evaluation Dimension</th><th>Application Scenario</th><th>Implementation</th><th>Value Range</th><th>Interpretation</th><th>Advantages</th><th>Limitations</th></tr></thead><tbody><tr><td>BLEU Scorer</td><td>Fluency and Lexical Match</td><td>Machine Translation, Text Generation</td><td>Calculates precision based on n-gram matching by comparing n-grams in generated and reference texts</td><td>[0, 1]</td><td>Higher values indicate greater match between generated and reference texts</td><td>Suitable for large datasets, simple and efficient</td><td>Performs poorly at sentence level, insensitive to synonyms and word order</td></tr><tr><td>ROUGE Scorer</td><td>Content Overlap</td><td>Text Summarization</td><td>Calculates overlap between generated and reference summaries using n-gram and longest common subsequence matching</td><td>[0, 1]</td><td>Higher values indicate more content overlap between generated and reference texts</td><td>Easy to use, applicable to various text generation tasks</td><td>Limited semantic understanding</td></tr><tr><td>METEOR Scorer</td><td>Semantic Matching</td><td>Machine Translation</td><td>Calculates alignment scores between generated and reference texts based on stemming, synonym matching, and semantic relevance</td><td>[0, 1]</td><td>Higher values indicate stronger semantic consistency between generated and reference texts</td><td>More sensitive to semantic similarity than BLEU, closer to human evaluation</td><td>High computational complexity</td></tr><tr><td>CIDEr Scorer</td><td>Content Relevance</td><td>Image Caption Generation</td><td>Uses TF-IDF weighted n-gram statistics to compare similarity between generated and reference descriptions</td><td>[0, 1]</td><td>Higher values indicate stronger content consistency between generated and reference texts</td><td>Considers the weight of words in the reference text, suitable for image-to-text tasks</td><td>Strong influence of low-frequency words</td></tr><tr><td>CHRF Scorer</td><td>Lexical Matching</td><td>Machine Translation</td><td>Calculates the chrF score based on character-level n-gram precision and recall between the reference text and the evaluated text</td><td>[0, 1]</td><td>The higher the value, the stronger the semantic similarity</td><td>Allows for more fine-grained understanding</td><td>Ignores semantic information</td></tr></tbody></table><hr><h3 id="word-embeddings-based" tabindex="-1"><a class="header-anchor" href="#word-embeddings-based"><span>Word Embeddings Based</span></a></h3><table><thead><tr><th>Scorer Name</th><th>Evaluation Dimension</th><th>Application Scenario</th><th>Implementation</th><th>Value Range</th><th>Interpretation</th><th>Advantages</th><th>Limitations</th></tr></thead><tbody><tr><td>Embedding Average Score</td><td>Semantic Similarity</td><td>Text Generation</td><td>Computes cosine similarity of the average word embeddings of generated and reference texts</td><td>[0, 1]</td><td>Higher values indicate stronger semantic similarity</td><td>Simple and efficient, suitable for quick computations</td><td>Cannot capture complex semantic structures</td></tr><tr><td>Greedy Matching Score</td><td>Semantic Relevance</td><td>Text Generation</td><td>Matches semantically similar words between generated and reference texts, computes similarity</td><td>[0, 1]</td><td>Higher values indicate stronger semantic relevance</td><td>Captures local similarity</td><td>Ignores global semantic structure</td></tr></tbody></table><hr><h3 id="language-models-based" tabindex="-1"><a class="header-anchor" href="#language-models-based"><span>Language Models Based</span></a></h3><table><thead><tr><th>Scorer Name</th><th>Evaluation Dimension</th><th>Application Scenario</th><th>Implementation</th><th>Value Range</th><th>Interpretation</th><th>Advantages</th><th>Limitations</th></tr></thead><tbody><tr><td>WSD Scorer</td><td>Semantic Similarity</td><td>Text Generation, Semantic Similarity Analysis</td><td>Uses word2vec to calculate Word Mover&#39;s Distance (WMD) between generated and reference texts</td><td>[0, +∞)</td><td>Lower values indicate closer semantic distance between generated and reference texts</td><td>Captures deep semantic differences, applicable to various languages</td><td>Sensitive to text length and stopwords, high computational complexity</td></tr><tr><td>BertScore</td><td>Semantic Similarity</td><td>Text Generation</td><td>Computes similarity of word embeddings between generated and reference texts using BERT</td><td>[0, 1]</td><td>Higher values indicate stronger semantic similarity between generated and reference texts</td><td>Captures deep semantic information, supports multiple languages</td><td>Depends on pre-trained models, time-consuming computations</td></tr><tr><td>BARTScore</td><td>Fluency and Informativeness</td><td>Text Generation</td><td>Uses BART model to treat the generated text as the target and computes the likelihood score</td><td>(-∞, +∞)</td><td>Higher values indicate better quality of generated text</td><td>Provides a multi-dimensional evaluation of text quality</td><td>Strong dependency on models</td></tr><tr><td>BELURT Scorer</td><td>Semantic Similarity</td><td>Text Generation, Machine Translation</td><td>Fine-tunes pre-trained language models (e.g., BERT) for semantic similarity tasks, computes similarity scores between generated and reference texts</td><td>[0, 1]</td><td>Higher values indicate stronger semantic consistency between generated and reference texts</td><td>Combines semantic understanding of pre-trained models, captures deep semantic information</td><td>Model training depends on high-quality data, sensitive to domain changes, and computationally expensive</td></tr></tbody></table><hr><h3 id="others" tabindex="-1"><a class="header-anchor" href="#others"><span>Others</span></a></h3><table><thead><tr><th>Scorer Name</th><th>Evaluation Dimension</th><th>Application Scenario</th><th>Implementation</th><th>Value Range</th><th>Interpretation</th><th>Advantages</th><th>Limitations</th></tr></thead><tbody><tr><td>TER Scorer</td><td>Edit Distance</td><td>Machine Translation</td><td>Calculates the minimum edit operations (insertions, deletions, and substitutions) needed to transform generated text into reference text</td><td>[0, 1]</td><td>Lower values indicate closer match between generated and reference texts</td><td>Simple and intuitive, suitable for analyzing errors in machine translation</td><td>Insensitive to semantic information</td></tr><tr><td>HLEPOR Scorer</td><td>Multi-Dimensional Matching</td><td>Machine Translation</td><td>Calculates multi-dimensional matching scores between generated and reference texts considering multiple weighted parameters (e.g., position, proportion)</td><td>[0, 1]</td><td>Higher values indicate stronger match between generated and reference texts</td><td>Highly flexible, adjustable weight parameters to fit different tasks</td><td>Parameter selection significantly affects evaluation results</td></tr></tbody></table>',14)]))}const c=e(r,[["render",i]]),l=JSON.parse('{"path":"/en/guide/zwu1hdwq/","title":"Generated Text Data Evaluation Metrics","lang":"en-US","frontmatter":{"title":"Generated Text Data Evaluation Metrics","createTime":"2025/06/09 11:43:25","permalink":"/en/guide/zwu1hdwq/"},"readingTime":{"minutes":2.53,"words":759},"git":{"createdTime":1749441278000,"updatedTime":1750128958000,"contributors":[{"name":"Sunnyhaze","username":"Sunnyhaze","email":"mxch1122@126.com","commits":1,"avatar":"https://avatars.githubusercontent.com/Sunnyhaze?v=4","url":"https://github.com/Sunnyhaze"},{"name":"Ma, Xiaochen","username":"","email":"mxch1122@126.com","commits":1,"avatar":"https://gravatar.com/avatar/c86bc98abf428aa442dfc12c76e70e324a551ebc637e5ed6634d60fbd3811221?d=retro"}]},"filePathRelative":"en/notes/guide/metrics/gen_text_metrics.md","headers":[]}');export{c as comp,l as data};
